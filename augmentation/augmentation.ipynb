{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any\n",
    "from PIL import Image\n",
    "from shapely.geometry import Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_show(img:Any,title:str=\"\")->None:\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def simple_shows(args: list[dict[str, Any]]) -> None:\n",
    "    len_args = len(args)\n",
    "    try:\n",
    "        heights = [img.size[1] for img in [arg['img'] for arg in args]]\n",
    "        widths = [img.size[0] for img in [arg['img'] for arg in args]]\n",
    "    except Exception:\n",
    "        heights = [np.array(arg['img']).shape[0] for arg in args]\n",
    "        widths = [np.array(arg['img']).shape[1] for arg in args]\n",
    "    \n",
    "    avg_height = sum(heights) / len_args\n",
    "    avg_width = sum(widths) / len_args\n",
    "    aspect_ratio = avg_height / avg_width\n",
    "\n",
    "    fig_width = len_args * 4\n",
    "    fig_height = fig_width * aspect_ratio\n",
    "    \n",
    "    fig, axs = plt.subplots(1, len_args, figsize=(fig_width, fig_height))\n",
    "    for i in range(len_args):\n",
    "        title = args[i].get('title', '')\n",
    "        img = args[i].get('img', None)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_dir(fname):\n",
    "    lang_indicator = fname.split('.')[1]\n",
    "    if lang_indicator == 'zh':\n",
    "        lang = 'chinese'\n",
    "    elif lang_indicator == 'ja':\n",
    "        lang = 'japanese'\n",
    "    elif lang_indicator == 'th':\n",
    "        lang = 'thai'\n",
    "    elif lang_indicator == 'vi':\n",
    "        lang = 'vietnamese'\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return osp.join('../data', f'{lang}_receipt', 'img', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lang_list = ['chinese', 'japanese', 'thai', 'vietnamese']\n",
    "\n",
    "total_anno = dict(images=dict())\n",
    "for nation in _lang_list:\n",
    "    with open(osp.join('../data', '{}_receipt/ufo/{}.json'.format(nation, 'train')), 'r', encoding='utf-8') as f:\n",
    "        anno = json.load(f)\n",
    "    for im in anno['images']:\n",
    "        total_anno['images'][im] = anno['images'][im]\n",
    "\n",
    "    anno = total_anno\n",
    "    image_fnames = sorted(anno['images'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fname = image_fnames[idx]\n",
    "image_fpath = osp.join(_infer_dir(image_fname), image_fname)\n",
    "original_image = Image.open(image_fpath)\n",
    "\n",
    "vertices, labels = [], []\n",
    "for word_info in anno['images'][image_fname]['words'].values():\n",
    "    num_pts = np.array(word_info['points']).shape[0]\n",
    "    if num_pts > 4:\n",
    "        continue\n",
    "    vertices.append(np.array(word_info['points']).flatten())\n",
    "    labels.append(1)\n",
    "vertices, labels = np.array(vertices, dtype=np.float32), np.array(labels, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotate_mat(theta):\n",
    "    '''positive theta value means rotate clockwise'''\n",
    "    return np.array([[math.cos(theta), -math.sin(theta)], [math.sin(theta), math.cos(theta)]])\n",
    "\n",
    "def rotate_vertices(vertices, theta, anchor=None):\n",
    "    '''rotate vertices around anchor\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "        theta   : angle in radian measure\n",
    "        anchor  : fixed position during rotation\n",
    "    Output:\n",
    "        rotated vertices <numpy.ndarray, (8,)>\n",
    "    '''\n",
    "    v = vertices.reshape((4,2)).T\n",
    "    if anchor is None:\n",
    "        anchor = v[:,:1]\n",
    "    rotate_mat = get_rotate_mat(theta)\n",
    "    res = np.dot(rotate_mat, v - anchor)\n",
    "    return (res + anchor).T.reshape(-1)\n",
    "\n",
    "def rotate_img(img, vertices, angle_range=10):\n",
    "    '''rotate image [-10, 10] degree to aug data\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        angle_range : rotate range\n",
    "    Output:\n",
    "        img         : rotated PIL Image\n",
    "        new_vertices: rotated vertices\n",
    "    '''\n",
    "    center_x = (img.width - 1) / 2\n",
    "    center_y = (img.height - 1) / 2\n",
    "    angle = angle_range * (np.random.rand() * 2 - 1)\n",
    "    img = img.rotate(angle, Image.BILINEAR)\n",
    "    new_vertices = np.zeros(vertices.shape)\n",
    "    for i, vertice in enumerate(vertices):\n",
    "        new_vertices[i,:] = rotate_vertices(vertice, -angle / 180 * math.pi, np.array([[center_x],[center_y]]))\n",
    "    return img, new_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img, vertices, size):\n",
    "    h, w = img.height, img.width\n",
    "    ratio = size / max(h, w)\n",
    "    if w > h:\n",
    "        img = img.resize((size, int(h * ratio)), Image.BILINEAR)\n",
    "    else:\n",
    "        img = img.resize((int(w * ratio), size), Image.BILINEAR)\n",
    "    new_vertices = vertices * ratio\n",
    "    return img, new_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_height(img, vertices, ratio=0.2):\n",
    "    '''adjust height of image to aug data\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        ratio       : height changes in [0.8, 1.2]\n",
    "    Output:\n",
    "        img         : adjusted PIL Image\n",
    "        new_vertices: adjusted vertices\n",
    "    '''\n",
    "    ratio_h = 1 + ratio * (np.random.rand() * 2 - 1)\n",
    "    old_h = img.height\n",
    "    new_h = int(np.around(old_h * ratio_h))\n",
    "    img = img.resize((img.width, new_h), Image.BILINEAR)\n",
    "\n",
    "    new_vertices = vertices.copy()\n",
    "    if vertices.size > 0:\n",
    "        new_vertices[:,[1,3,5,7]] = vertices[:,[1,3,5,7]] * (new_h / old_h)\n",
    "    return img, new_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cross_text(start_loc, length, vertices):\n",
    "    '''check if the crop image crosses text regions\n",
    "    Input:\n",
    "        start_loc: left-top position\n",
    "        length   : length of crop image\n",
    "        vertices : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "    Output:\n",
    "        True if crop image crosses text region\n",
    "    '''\n",
    "    if vertices.size == 0:\n",
    "        return False\n",
    "    start_w, start_h = start_loc\n",
    "    a = np.array([start_w, start_h, start_w + length, start_h, start_w + length, start_h + length,\n",
    "                  start_w, start_h + length]).reshape((4, 2))\n",
    "    p1 = Polygon(a).convex_hull\n",
    "    for vertice in vertices:\n",
    "        p2 = Polygon(vertice.reshape((4, 2))).convex_hull\n",
    "        inter = p1.intersection(p2).area\n",
    "        if 0.01 <= inter / p2.area <= 0.99:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, vertices, labels, length):\n",
    "    '''crop img patches to obtain batch and augment\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        labels      : 1->valid, 0->ignore, <numpy.ndarray, (n,)>\n",
    "        length      : length of cropped image region\n",
    "    Output:\n",
    "        region      : cropped image region\n",
    "        new_vertices: new vertices in cropped region\n",
    "    '''\n",
    "    h, w = img.height, img.width\n",
    "    # confirm the shortest side of image >= length\n",
    "    if h >= w and w < length:\n",
    "        img = img.resize((length, int(h * length / w)), Image.BILINEAR)\n",
    "    elif h < w and h < length:\n",
    "        img = img.resize((int(w * length / h), length), Image.BILINEAR)\n",
    "    ratio_w = img.width / w\n",
    "    ratio_h = img.height / h\n",
    "    assert(ratio_w >= 1 and ratio_h >= 1)\n",
    "\n",
    "    new_vertices = np.zeros(vertices.shape)\n",
    "    if vertices.size > 0:\n",
    "        new_vertices[:,[0,2,4,6]] = vertices[:,[0,2,4,6]] * ratio_w\n",
    "        new_vertices[:,[1,3,5,7]] = vertices[:,[1,3,5,7]] * ratio_h\n",
    "\n",
    "    # find random position\n",
    "    remain_h = img.height - length\n",
    "    remain_w = img.width - length\n",
    "    flag = True\n",
    "    cnt = 0\n",
    "    while flag and cnt < 1000:\n",
    "        cnt += 1\n",
    "        start_w = int(np.random.rand() * remain_w)\n",
    "        start_h = int(np.random.rand() * remain_h)\n",
    "        flag = is_cross_text([start_w, start_h], length, new_vertices[labels==1,:])\n",
    "    box = (start_w, start_h, start_w + length, start_h + length)\n",
    "    region = img.crop(box)\n",
    "    if new_vertices.size == 0:\n",
    "        return region, new_vertices\n",
    "\n",
    "    new_vertices[:,[0,2,4,6]] -= start_w\n",
    "    new_vertices[:,[1,3,5,7]] -= start_h\n",
    "    return region, new_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = original_image\n",
    "if original_image.mode != 'RGB':\n",
    "    image = original_image.convert('RGB')\n",
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = []\n",
    "# funcs.append(A.GaussianBlur(p=1))\n",
    "# funcs.append(A.Blur(p=1))\n",
    "# funcs.append(A.AdvancedBlur(p=1))\n",
    "# funcs.append(A.UnsharpMask(p=1))\n",
    "# funcs.append(A.ToSepia(p=1))\n",
    "# funcs.append(A.Superpixels(p=1))\n",
    "# funcs.append(A.Sharpen(p=1))\n",
    "# funcs.append(A.RandomSunFlare(p=1))\n",
    "# funcs.append(A.RandomToneCurve(p=1))\n",
    "# funcs.append(A.RandomBrightnessContrast(p=1))\n",
    "# funcs.append(A.Posterize(p=1))\n",
    "# funcs.append(A.CLAHE(p=1))\n",
    "# funcs.append(A.RandomGravel(p=1))\n",
    "# funcs.append(A.PlanckianJitter(p=1))\n",
    "# funcs.append(A.PixelDropout(p=1))\n",
    "# funcs.append(A.Morphological(operation='dilation', p=1))\n",
    "# funcs.append(A.Morphological(operation='erosion', p=1))\n",
    "# funcs.append(A.ChannelShuffle(p=1))\n",
    "# funcs.append(A.ChromaticAberration(p=1))\n",
    "# funcs.append(A.GaussNoise(p=1))\n",
    "# funcs.append(A.ISONoise(p=1))\n",
    "# funcs.append(A.RandomFog(p=1))\n",
    "# funcs.append(A.ImageCompression(p=1))\n",
    "# funcs.append(A.GaussianBlur(p=1))\n",
    "# funcs.append(A.ColorJitter(p=1))\n",
    "# funcs.append(A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)))\n",
    "transform = A.Compose(funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize\n",
    "resize_image, vertices = resize_img(original_image, vertices, 2048)\n",
    "\n",
    "simple_shows([{\n",
    "    'img':original_image,\n",
    "    'title':\"Original Image\"\n",
    "},{\n",
    "    'img':resize_image,\n",
    "    'title':\"Resize Image\"\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate\n",
    "rotate_image, vertices = rotate_img(original_image, vertices)\n",
    "\n",
    "simple_shows([{\n",
    "    'img':original_image,\n",
    "    'title':\"Original Image\"\n",
    "},{\n",
    "    'img':rotate_image,\n",
    "    'title':\"Rotated Image\"\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop\n",
    "crop_image, vertices = crop_img(original_image, vertices, labels, 1024)\n",
    "\n",
    "simple_shows([{\n",
    "    'img':original_image,\n",
    "    'title':\"Original Image\"\n",
    "},{\n",
    "    'img':crop_image,\n",
    "    'title':\"Crop Image\"\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust_height\n",
    "adjust_height_image, vertices = adjust_height(original_image, vertices)\n",
    "\n",
    "simple_shows([{\n",
    "    'img':original_image,\n",
    "    'title':\"Original Image\"\n",
    "},{\n",
    "    'img':adjust_height_image,\n",
    "    'title':\"Adjust Height Image\"\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentation augmentation\n",
    "color_image = transform(image=image)['image']\n",
    "\n",
    "simple_shows([{\n",
    "    'img':original_image,\n",
    "    'title':\"Original Image\"\n",
    "},{\n",
    "    'img':color_image,\n",
    "    'title':\"augmentation Image\"\n",
    "}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
